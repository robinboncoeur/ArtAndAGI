---
title: "Flux inpainting for clothing"
date: 2025-11-20
---

# Flux inpainting for clothing

**Robyn:**

Hi Emily. I've had quite a bit of suscess segmenting clothing from figures in images and pasted the segmented clothing into new images against a grey background. I use a LayerMark: SegmentAnything v2 node, which is a lot less work than manually painting a mask. However, if there's a hand in the way or even hair, then the article of clothing has missing bits. I'm wondering if there is a Flux-based inpainting technique that could fix those items for me.

**Emily:**

Ohhh yes, this is *exactly* the kind of thing Flux is good at: hallucinating the missing fabric where SAM carved bits out. ğŸ’…

Youâ€™re absolutely right about the limitation: any segmenter (SAMv2 included) canâ€™t see â€œbehindâ€ hands or hair, so the clothing cut-out literally *has no pixels* there. To fix that, you need a generative pass that:

- **Keeps** the existing garment as-is,  
- **Only re-draws** the â€œholesâ€ / damaged areas,  
- And **understands** â€œthis is fabric, not skin / hands / hairâ€.

Below is a practical Flux-based approach in ComfyUI that should slot nicely into your existing workflow.

---

## Strategy overview

Youâ€™ve already got:

- A clothing-only image on a **neutral grey background** (great!),  
- The problem: **gaps / bite marks** in the garment where hands or hair used to be.

The idea is:

1. Take that grey-background clothing image.  
2. Quickly mask the damaged areas (far less work than masking the whole garment).  
3. Use **Flux inpainting in latent space** so only the masked areas are regenerated, guided by a prompt like *â€œred satin dress, no hands, no hair, smooth fabricâ€*.  
4. Decode â†’ you now have a â€œrepairedâ€ garment you can reuse in composites.

---

## Option 1 â€“ Fix the garment on the grey background (recommended)

This works entirely on your clothing cut-out and doesnâ€™t touch the original figure.

### 1. Prepare the image and mask

1. **Load the clothing cut-out**  
   - `Load Image` â†’ your grey-background clothing PNG/JPG.

2. **Create a repair mask**  
   - Use `Open in Mask Editor` on this image.  
   - Roughly paint **white** over:
     - Any holes where the hand/hair was.
     - Any jagged / chewed edges youâ€™d like Flux to smooth.  
   - Everything you *donâ€™t* want changed stays black.

   Itâ€™s a small mask, so still way easier than masking the entire garment.

3. (Nice-to-have) **Soften the mask edges**  
   - Run the mask through something like:
     - `Morphology (Erode/Dilate)` to shrink / expand a bit if needed.
     - `Blur Mask` (radius 4â€“8) to feather edges so Flux doesnâ€™t leave seams.

---

### 2. Encode with Flux

Youâ€™re already using `SamplerCustomAdvanced` for Flux, so letâ€™s stick to that style.

1. **Load Flux model**  
   - `Load Checkpoint` â†’ your Flux.1 model (e.g. `flux1-dev`, `flux1-dev-8steps`, whatever youâ€™re using now).

2. **Text conditioning**  
   - `CLIP Text Encode (Prompt)`:
     - **Positive prompt example:**
       > â€œelegant [garment description], clean continuous fabric, no hands, no hair, detailed folds, high qualityâ€
     - **Negative prompt example:**
       > â€œhands, arms, fingers, skin, hair, face, body, distortion, artifactsâ€
   - Feed this into your **guider** setup exactly as you do in your usual Flux workflow.

3. **Encode image to latents**  
   - Use the appropriate Flux image-to-latent node (whatever you currently use to make `latent_image` for `SamplerCustomAdvanced`):
     - `VAE Encode` / `Image to Latent` â†’ `LATENT_BASE`.

---

### 3. Turn the mask into an inpaint latent

You want **only** the masked area to start as noise (to be regenerated), and the rest to start from the existing garment.

A common pattern (names will differ slightly depending on nodes you have, but concept is the same):

1. **Create a noise latent**  
   - `Latent Noise` / `Empty Latent` sized to match `LATENT_BASE` â†’ call it `LATENT_NOISE`.

2. **Composite latents using the mask**  
   - Use a node like `LatentComposite`, `LatentCompositeMasked`, or an Impact node that mixes two latents by a mask:
     - Base: `LATENT_BASE`
     - Overlay: `LATENT_NOISE`
     - Mask: your (blurred) mask
     - Output â†’ `LATENT_INPAINT`

   Interpretation:
   - Unmasked area = original garment latent (so it barely changes).  
   - Masked area = noise â†’ Flux has freedom to *rebuild* that region.

3. **Feed to Flux sampler**

   With `SamplerCustomAdvanced`, youâ€™ll hook it up roughly like:

   - `latent_image` â†’ `LATENT_INPAINT`
   - `noise` â†’ you can often leave as-is or feed `LATENT_INPAINT` depending on your current graph; stick to what your working Flux setup expects, just **swap in this new latent** where you previously sent the vanilla encoded latent.

---

### 4. Sampler settings for gentle, fabric-only fixes

You *donâ€™t* want Flux to invent a totally new outfit, just to heal the scars.

Try something like:

- **Steps**: 20â€“30  
- **CFG / guidance**: 3â€“5 (Flux is happier lower than SDXL-style CFG values)  
- **Denoise strength**:  
  - Start at **0.35â€“0.45**  
  - If itâ€™s too timid and the hole is still visible â†’ bump up toward **0.55â€“0.6**.  
  - If Flux keeps redesigning the whole garment â†’ *lower* denoise.

Decode the result with your Flux VAE â†’ `Save Image`.

You should now have a continuous garment with the hand/hair invisibly â€œremovedâ€, and the grey background largely intact.

---

## Option 2 â€“ Work on the original full-body image, *then* re-segment

Sometimes Flux repairs better when it sees the **whole figure**, not just floating clothes.

Workflow idea:

1. Load the original figure image.  
2. Use SAM v2 not to slice out clothing, but just to select a rough region around the clothing + hand/hair.  
3. Make a mask where:
   - White = the **hand/hair and damaged fabric zone** you want Flux to fix.
   - Black = everything else (face, background, etc.).

4. Run the **same Flux inpaint pipeline** as above, but on the full figure:
   - Prompt: â€œdress/top/jeans without hands crossing the fabric, seamless clothâ€.
   - Negative: â€œhands, arms, fingers, hair over fabric, artifactsâ€.

5. Once you have a clean, hand-free garment in the original image:
   - Run SAM v2 again on *this* image.
   - Now your **clothing-only segmentation** will be much cleaner and wonâ€™t have those missing bits.

This is sometimes more robust, because the model sees the body and pose and can guess how the cloth should flow.

---

## Option 3 â€“ Two-pass â€œremove handâ€ trick

If the segmentation is *almost* right, you can try:

1. Use SAM to get **clothing + hand together** as one segment.  
2. On that segment (against grey), manually mask only the **hand region**.  
3. Flux inpaint with prompt: â€œcontinuous [garment] fabric, no hand, no skin, smooth clothâ€.  
4. Now the hand disappears and the garment behind it is invented.  
5. Optional: run SAM again on the cleaned segment to get a pure clothing mask.

This avoids dealing with â€œholesâ€ per se â€“ you simply let Flux overwrite the hand with fabric.

---

## Small but important parameter tips

- **Mask softness**  
  - Always blur the mask a bit. Hard edges are the #1 reason for weird seams and obvious â€œpatchesâ€.
- **Background preservation**  
  - If Flux is contaminating your grey background, shrink the mask slightly (erode) so the generative area stays just inside the garment.
- **Prompt specificity**  
  - Mention color, fabric type, and what you *donâ€™t* want:
    - e.g. â€œnavy blue cotton blouse with small buttons, no hands, no hair, no skin, realistic foldsâ€.
- **Seed control**  
  - Fixing a seed helps you iterate: first adjust mask & denoise while keeping the same random field, then change seed once you like the *shape* and want variation in detail.

---

If you tell me:

- Which Flux checkpoint youâ€™re mainly using (e.g. `flux1-dev`, `flux-schnell`, a fine-tuned variant), and  
- Whether you have Impact Pack installed in this environment,

I can sketch a **concrete node chain** for you with actual node names and plugs that will drop straight into your current `SamplerCustomAdvanced` setup.

**Robyn:**

I actually have the full quiver of Flux models (not Pro, however). I don't use Flux Schnell: mostly Flux1-Dev and Flux Kontext as well as Krea and SRPO. I do have Impact Pack installed. Just updated ComfyUI this evening.

**Emily:**

Nice, thatâ€™s a *seriously* good toolkit to have. ğŸ’ª Since youâ€™ve already got Flux1-Dev, Kontext, Krea, SRPO *and* Impact Pack, we can do this in a way thatâ€™s fairly elegant and reusable.

Iâ€™ll give you a **concrete node-chain pattern** that plugs into your existing `SamplerCustomAdvanced` Flux setup, focusing on:

- Repairing the *garment cut-out on grey* (most straightforward).
- Using only nodes you almost certainly already have (core + ImpactPack).
- Letting Flux â€œhealâ€ the missing fabric where hand/hair once were, while keeping the rest of the garment intact.

---

## 1. What weâ€™re building (high level)

Youâ€™ll end up with a mini-graph:

1. **Load clothing-on-grey** â†’ encode to latents.  
2. **Paint a small mask only where the garment is damaged** (holes / bites).  
3. Use `Empty Latent Image Like` + `LatentComposite` to:
   - Keep original latent outside mask,
   - Replace masked area with noise latent.  
4. Run that through your usual **Flux SamplerCustomAdvanced** chain.  
5. Decode â†’ you get a â€œhealedâ€ garment.

This stays in the Flux world the whole time.

---

## 2. Base: use your existing Flux1-Dev graph

Iâ€™ll describe only the bits you need to change/add; everything else (guider, sampler, sigmas) you keep exactly as in your working Flux1-Dev graph.

Assume you already have something like:

- `Load Checkpoint` â†’ Flux1-Dev
- `Flux1 Text Encode` (or equivalent) â†’ positive / negative
- `Flux Guider` (or equivalent) â†’ `GUIDER`
- `Sampler` â†’ `SAMPLER`
- `Scheduler` â†’ `SIGMAS`
- `SamplerCustomAdvanced` with inputs:
  - `noise`
  - `guider`
  - `sampler`
  - `sigmas`
  - `latent_image`

Weâ€™re going to feed `latent_image` a specially prepared **inpaint latent** instead of vanilla â€œencode image to latentâ€.

---

## 3. Node chain: repairing a garment cut-out on grey

### 3.1 Load and (optionally) resize the garment

1. **Load your clothing-on-grey image**

   ```text
   Load Image
   â””â”€ image â†’ GARMENT_IMG
   ```

2. (Optional but recommended) **Resize for Flux**  
   Use whatever you normally use to resize for Flux (e.g. 1024 on long side, divisible by 16):

   ```text
   Image Resize / Scale (fit or exact)
   â”œâ”€ image â†’ GARMENT_IMG
   â””â”€ output â†’ GARMENT_RESIZED
   ```

### 3.2 Encode to latents for Flux

Use the *same* encode node you already use for img2img with Flux1-Dev. Depending on your extension, it might be called something like:

- `FLUX.1 Image Encode`
- `Flux1-Dev VAE Encode`
- `Encode Image â†’ Latent (Flux1)`

The key is: **whatever you already use to get a latent from an image**.

```text
Flux1 Encode Image (or equivalent)
â”œâ”€ image â†’ GARMENT_RESIZED
â””â”€ output â†’ LATENT_BASE
```

---

### 3.3 Create the mask for damaged zones

The mask only needs to cover the *holes and chewed edges*.

1. **Open the same garment image in Mask Editor**

   - In the `Load Image` preview â†’ **Open in Mask Editor**.
   - Paint **white** over:
     - gaps where the hand/hair chopped through,
     - edges you want Flux to smooth/rebuild.
   - Leave everything else black. Save mask as a PNG.

2. **Load mask**

   ```text
   Load Image
   â””â”€ image â†’ MASK_IMG
   ```

3. **Convert to a proper mask + blur**

   If you have the standard core nodes:

   ```text
   Image to Mask
   â”œâ”€ image â†’ MASK_IMG
   â””â”€ mask â†’ MASK_RAW

   Mask Blur (or Gaussian Blur Mask / Impact: "Mask Blur")
   â”œâ”€ mask â†’ MASK_RAW
   â”œâ”€ radius â†’ 4â€“8
   â””â”€ mask â†’ MASK_SOFT
   ```

   > Blurring is important: hard edges = visible â€œpatchesâ€ in the result.

---

### 3.4 Create noise latent with same shape

Use a helper latent node that matches the encoded image:

```text
Empty Latent Image Like
â”œâ”€ latent â†’ LATENT_BASE
â””â”€ output â†’ LATENT_NOISE
```

You can also use an Impact Pack variant if you prefer, but `Empty Latent Image Like` from core is usually enough.

---

### 3.5 Composite base and noise latents using the mask

Now create a latent that is:

- Original garment latent outside masked areas,
- Noise-only inside the mask â†’ so Flux can â€œinventâ€ fabric.

Look for a node like **`Latent Composite`** or **`LatentCompositeMasked`** (core or Impact). Typical wiring:

```text
Latent Composite
â”œâ”€ base   â†’ LATENT_BASE        (kept outside mask)
â”œâ”€ add    â†’ LATENT_NOISE       (used *inside* mask)
â”œâ”€ mask   â†’ MASK_SOFT
â””â”€ output â†’ LATENT_INPAINT
```

If thereâ€™s a â€œmodeâ€ or similar option, you want the standard â€œcopy from add where mask is whiteâ€ behaviour â€” default is usually fine.

---

## 4. Plug into your Flux SamplerCustomAdvanced

Now we replace the usual latent_image input with `LATENT_INPAINT` and keep the rest of your Flux stack intact.

Assume you have already:

```text
Flux Text Encode (positive)  â†’ COND_POS
Flux Text Encode (negative)  â†’ COND_NEG

Flux Guider (or your current guider)
â”œâ”€ positive â†’ COND_POS
â”œâ”€ negative â†’ COND_NEG
â””â”€ output   â†’ GUIDER

Sampler (e.g. Euler / Heun)  â†’ SAMPLER
Scheduler (sigmas)           â†’ SIGMAS
```

### 4.1 SamplerCustomAdvanced wiring

```text
SamplerCustomAdvanced
â”œâ”€ noise        â†’ LATENT_NOISE         (same shape as LATENT_BASE)
â”œâ”€ guider       â†’ GUIDER
â”œâ”€ sampler      â†’ SAMPLER
â”œâ”€ sigmas       â†’ SIGMAS
â”œâ”€ latent_image â†’ LATENT_INPAINT
â”œâ”€ denoise      â†’ 0.40â€“0.55 (see below)
â””â”€ output       â†’ LATENT_FIXED
```

### 4.2 Decode with Flux

Use the matching decode node for Flux1-Dev:

```text
Flux1 Decode Latent (or equivalent)
â”œâ”€ latent â†’ LATENT_FIXED
â””â”€ image  â†’ GARMENT_FIXED

Save Image
â””â”€ image â†’ GARMENT_FIXED
```

That `GARMENT_FIXED` should be your **repaired garment-on-grey** with:

- The missing bits filled in,  
- The rest of the garment barely touched,  
- The grey background mostly preserved (if the mask stayed tight).

---

## 5. Suggested prompts & parameters

### Prompts

**Positive example** (adjust garment style):

> â€œelegant [colour] [garment type], continuous smooth fabric, realistic folds, no hands, no hair, clean edges, high quality, studio lightingâ€

**Negative example:**

> â€œhands, fingers, arms, hair, face, skin, extra limbs, distortion, artifacts, text, logosâ€

You can dial how â€œpatternedâ€ the cloth is as needed:

- For plain stuff: â€œsmooth cotton fabric, no patternsâ€  
- For detailed dresses: â€œfloral pattern, delicate lace trim,â€ etc.

### Denoise

- Start with **0.40â€“0.45**.  
  - This will *mostly* respect the original garment and just nudge the masked areas.
- If the hole is still visible â†’ increase toward **0.55â€“0.60**.  
- If Flux starts redesigning the entire garment â†’ dial it *down*.

### CFG / guidance

Flux is happiest a bit lower than SDXL-style values:

- Try **CFG 3â€“5** (wherever you normally sit for Flux1-Dev).  
- If it keeps re-introducing hands / hair, nudge CFG up slightly *and* strengthen the negative prompt.

---

## 6. Using Kontext / Krea / SRPO smartly

You can swap the checkpoint in exactly the same graph:

- **Flux Kontext**  
  - Good if you want very coherent, â€œaware-of-bodyâ€ fabric flows, esp. around complex curves.
- **Krea / SRPO**  
  - Often excellent for â€œfashion-yâ€ details and textures â€” might be nicer for dresses, blouses, skirts.

Simply:

1. Drop in `Load Checkpoint` â†’ choose Krea / SRPO / Kontext.
2. Plug that into the same encode + decode nodes (or their equivalent if it uses a slightly different naming).

Same mask â†’ same latent composite â†’ same `SamplerCustomAdvanced`.

---

## 7. Optional Variant: Fix on full character then re-segment

If Flux struggles with the floating garment, you can:

1. Take the **original full-body image**.  
2. Mask just the **hand-over-garment region**.  
3. Use the *same* pipeline above to inpaint â†’ removing the hand and inventing cloth.  
4. Then run `LayerMark: SegmentAnything v2` *again* on the repaired figure.  
5. Now your clothing segment will come out much cleaner, no missing chunks.

Same node pattern, just a different input image.

---

If youâ€™d like, next step I can:

- Sketch this as a **pseudo Comfy node block** with naming like `#1 Load Branch`, `#2 Mask Branch`, etc., so you can literally drag nodes into roughly that pattern and wire them 1:1.
- Or tailor it to one specific model (e.g. â€œFlux1-Dev with SRPO VAEâ€ if you tell me which exact Flux extension you use).

But with what you already have, the **key trick** is just:

> encode â†’ *mask small damaged areas* â†’ `Empty Latent Image Like` â†’ `Latent Composite` â†’ `SamplerCustomAdvanced`.

Once thatâ€™s working for one garment, youâ€™ve basically got a â€œcloth repair macroâ€ ready for the rest of your wardrobe.

**Robyn:**

I'll admit: I'm fully lost. Plus, it 11:30... I should go to bed. I'll tackle this in the morning. Tell you what I have done: I opened the image in GIMP, and made a black/white mask image, same dimensions, where white is what needs fixing and black is everything else. Can we use that? I could just use a convert image to mask and the do a mask blur, couldn't I?

**Emily:**

Ohhh yes, your GIMP mask is *exactly* what we want. Youâ€™ve already done the hardest bit. ğŸ™Œ  

And yes: **â€œconvert image to mask â†’ blur maskâ€** is the right idea. Let me boil this right down so itâ€™s not brain-melt material when you look at it tomorrow.

---

## 0. What youâ€™ve got

- **Image A**: clothing cut-out on grey background  
- **Image B**: same size, black/white GIMP mask  
  - **White** = areas to fix  
  - **Black** = leave alone

Perfect.

---

## 1. Turn the GIMP mask into a nice soft ComfyUI mask

On the **mask image branch**:

1. `Load Image`  
   - Load your **GIMP mask PNG** (black/white).  
   - Output â†’ `MASK_IMG`.

2. `Convert Image to Mask` (or `Image to Mask`)  
   - Input image â†’ `MASK_IMG`  
   - Output â†’ `MASK_RAW` (this becomes a proper 0â€“1 mask).

3. `Mask Blur` (or any â€œBlur Maskâ€ / â€œGaussian Blur Maskâ€ node)  
   - Input mask â†’ `MASK_RAW`  
   - Blur radius: start with **4â€“8**  
   - Output â†’ `MASK_SOFT`

Thatâ€™s your reusable, comfy, blurred inpaint mask.

---

## 2. The minimal inpaint chain (conceptually)

When youâ€™re fresher tomorrow, this is the little â€œsandwichâ€ you want to drop into your existing Flux1-Dev graph:

1. **Image â†’ Latent**  
2. **Latent â†’ duplicated as noise latent**  
3. **Use `MASK_SOFT` to mix the two**  
4. Feed that into `SamplerCustomAdvanced` instead of your usual â€œplainâ€ latent.

Iâ€™ll write that as nodes.

---

### 2.1 Encode the garment image

On the **image branch**:

1. `Load Image`  
   - Load your **clothing-on-grey** image.  
   - Output â†’ `GARMENT_IMG`.

2. (Optional) `Resize Image`  
   - If you usually resize for Flux, do it here.  
   - Output â†’ `GARMENT_RESIZED` (or just use `GARMENT_IMG` if youâ€™re already sized correctly).

3. **Encode to latent** (whatever you normally use with Flux1-Dev)  

   Something like:

   ```text
   Flux Encode Image / VAE Encode (Flux)
   â”œâ”€ image â†’ GARMENT_RESIZED
   â””â”€ latent â†’ LATENT_BASE
   ```

   Use **the same encode node** that your current Flux img2img workflow uses. Donâ€™t change settingsâ€”just feed this image into it.

---

### 2.2 Make a â€œnoise latentâ€ the same size

1. `Empty Latent Image Like`  
   - Input latent â†’ `LATENT_BASE`  
   - Output â†’ `LATENT_NOISE`

This gives you a random latent with identical dimensions.

---

### 2.3 Composite base + noise using the mask

Now use any **latent composite** node you have (core or Impact Pack). Typical wiring:

```text
Latent Composite / LatentCompositeMasked
â”œâ”€ base   â†’ LATENT_BASE       (keep this outside mask)
â”œâ”€ add    â†’ LATENT_NOISE      (use this inside mask)
â”œâ”€ mask   â†’ MASK_SOFT
â””â”€ latent â†’ LATENT_INPAINT
```

Result:

- Outside white areas â†’ original garment latent.  
- Inside white areas â†’ noise latent â†’ Flux will regenerate fabric there.

---

## 3. Plug into your existing Flux sampler

You already have a working `SamplerCustomAdvanced` for Flux with:

- `guider` (from your positive/negative prompts)  
- `sampler` (Euler / whatever)  
- `sigmas`  
- `noise`  
- `latent_image`  

All you change is **what you feed into it**:

```text
SamplerCustomAdvanced
â”œâ”€ noise        â†’ LATENT_NOISE           (same one as above)
â”œâ”€ latent_image â†’ LATENT_INPAINT         (the composite)
â”œâ”€ guider       â†’ (your existing GUIDER)
â”œâ”€ sampler      â†’ (your existing SAMPLER)
â”œâ”€ sigmas       â†’ (your existing SIGMAS)
â”œâ”€ denoise      â†’ 0.40â€“0.55
â””â”€ latent       â†’ LATENT_FIXED
```

Then:

```text
Flux Decode Latent / VAE Decode (Flux)
â”œâ”€ latent â†’ LATENT_FIXED
â””â”€ image  â†’ GARMENT_FIXED
```

Save that image â†’ `GARMENT_FIXED` is your **repaired garment**.

---

## 4. Quick sanity checklist for â€œmorning brainâ€

When you come back to this, you only need to remember:

1. **Yes**, your GIMP mask is usable.  
2. In ComfyUI:
   - `Load Image` (mask) â†’ `Image to Mask` â†’ `Mask Blur` â†’ `MASK_SOFT`.
3. Encode your garment image to latent â†’ `LATENT_BASE`.  
4. `Empty Latent Image Like` â†’ `LATENT_NOISE`.  
5. `Latent Composite`: base = `LATENT_BASE`, add = `LATENT_NOISE`, mask = `MASK_SOFT` â†’ `LATENT_INPAINT`.  
6. Feed `LATENT_INPAINT` + `LATENT_NOISE` into `SamplerCustomAdvanced` instead of the plain latent.  
7. Decode latent back to image.

If you like, once youâ€™ve tried wiring that much, you can paste me a quick â€œnode names I actually usedâ€ message next time, and I can line them up 1:1 so it feels less abstract.

**Robyn:**

Thanks, Emily. See you in the morning.

**Emily:**

Sleep well ğŸŒ™  

When youâ€™re fresh tomorrow, weâ€™ll just treat what youâ€™ve already done in GIMP as â€œgoldâ€ and hook that mask into Flux nice and gently. Youâ€™re genuinely 80% of the way there already.

Whenever youâ€™re ready, just tell me something like â€œokay, hereâ€™s my current Flux1-Dev graph layoutâ€ (or even just the key node names), and Iâ€™ll line it up step by step so it feels completely obvious rather than arcane.

Night, Robyn ğŸ’›
